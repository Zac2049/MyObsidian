各位老师好，我是田沄教授的学生李鹏辉，很高兴参加今天的答辩，我的题目是基于全局频域及CLIP融合驱动的心脏语义分割
我将以以下四个方面进行我的答辩

社会问题上，心脏病一直是全球人类的主要死因。心脏病死亡人数比以往任何时候都多。自2000年以来，心脏病死亡人数增加了200多万。技术发展上，现代医学成像技术的发展为心脏结构定量评估提供了支持；医学心脏图像数据呈现指数增长；深度学习等技术和开源环境给予客观条件

•心脏子结构分割是心脏结构定量评估的一个重要的步骤。将解剖知识引入模型中，使医学结构的标注和病理的检测更加自动化和精细化，大大节省了人力；
•心脏图像往往有明确全局的纹理和形态结构，如何提取这些形态和纹理特征是研究的关键
•现代医学图像应用场景追求分割精度，也对模型参数量和计算量有所要求，如对实时性要求高的场景（如手术、超声等）、小型移动设备等
•分割算法集成和适应众多心脏医学数据集是一个挑战，因其覆盖面包括不同分布、不同形态和标签各异的情况。

心脏子结构分割分为传统和深度学习方法，传统方法基于图像处理和手工特征；深度学习，多阶段多视图分割，在方法上，心脏分割的标准网络采用UNet结构，细节设计结合CNN，Transformer，新型的MLP

连续情况的傅里叶变换我们都很熟悉，离散傅里叶变换又称DFT，逆离散傅里叶变换iDFT，
使得我们能在计算机中用矩阵乘法表示傅里叶变换。FFT快速傅里叶变换利用其周期性和对称性进行效率上的加速，近来有越来越多的工作集中于使用FFT加速深度学习训练和加速卷积的运算。

左边是心脏图像频域变换示例，傅里叶变换以及平移得到频谱，再高低通抑制，可以得到关于心脏图像的边缘和形态图像，右边是用resnet50每层输出的心脏图像的特征图，我们直观的也能看到关于边缘和形态的不同特征图
直观地说明我们在深度学习模型中学习心脏图像的模式本就在频域中有丰富的解释

由此提出GFBlock，全称Global Filter Block
GFBlock是本研究达到学习心脏图像全局频域信息的关键。GFBlock的构造思想很简单，每一层的GFBlock对整张feature做fft，在频域中进行全局计算以提取全局频域的特征 ，具体采取乘以可学习的矩阵，再做ifft变换到时域，再使用Layer Normalization对每层进行正则化

由此在GFBlock的基础上提出GFUNet
•图像分块给予位置编码，同ViT
•每一层不同大小的feature经过GFBlock学习全局频域的特征，再在时域下进行卷积下采样，完成一层的双域模块，以此重复四次每次图像特征在H,W两维度上缩小两倍
•编码器的最后一次GFBlock输入到bottleneck，再输入解码器
•解码器是残差，跳跃链接，反卷积的上采样的四次和编码器对应的循环，以及Deep Supervision对损失监督的优化

在设置上，指标本研究使用Dice评价分割精度，loss使用dice loss和交叉熵的加权

之后是实验和结果
首先本研究采用ACDC数据集，其含三个心脏结构标注，右心室、心肌、左心室

本研究在参数量、浮点运算量，平均dice分数三个指标上进行评估，和基于卷积的分割算法、基于Transformer/Swin Transformer的算法、基于MLP的分割算法上进行比较，可以发现本GFUNet能在参数量、运算量做到最优，在分割精度上会低于一些Transfromer的分割算法；
本研究还做了一个在ACDC上的分割可视化示例，在不同心脏图像帧上GFUNet都可以达到很高的细粒度。

其次与MICCAI M&Ms-2的历史竞赛参与者进行了对比，GFUNet在分割精度上能取得比其都高的结果。

本研究对GFUNet的设计进行消融实验，从最经典的UNet，到基于深度卷积的UNet，到GFBlock和卷积、MLP等的组合、最后有经典卷积解码器和本研究的解码器的对比
本研究还在不同通道上进行调整和设计，得到三个版本的GFUNet，其在参数量、运算量、精度上均有取舍。
最后本研究实现了2D GFUNet和3D GFUNet的比较，这里在2D基础上做一个三维医学图像的转变，实现很简单，具体来讲就是在编码器和解码器的 2d 卷积全换成 3d 卷积，全局频域块与之前的处理是一样的。
以上关于GFUNet的研究进行了整理，发了一篇期刊文章。

之后是第三章，CLIP 融合驱动的心脏语义分割
首先简单介绍下CLIP。用对比学习的方法来学习图像和文本的对应关系，每个匹配的文本和图像是一个训练的数据对，或者说正样本对，不匹配的就是负样本对。CLIP旨在聚集正样本对，扩大负样本之间的差异，由此能学习包含文本和图像的两个编码器。

预训练的编码器包含文本和图像的对齐编码信息，这些编码器进一步指导下游任务，诸如分类，分割等。
研究发现，CLIP具有开放词汇的零样本/少样本能力，模型可以在没有或几乎没有特定任务训练数据的情况下得到语义表示，利用这些编码器我能进一步指导下游视觉任务，如分割
在语义分割中利用prompt的CLIP编码信息能对我们需要的图像的编码空间中的元素进行拉近或者拉远。

集成部分标注的心脏数据集进行语义分割存在巨大的挑战。一是标签不一致，表现在五个方面。(i) 标注指标不一致。同一结构可以标注为不同的指标。 (ii) 名称语义不一致。如果多个命名标签指的是相同的解剖结构，命名可能会令人困惑，这与医学特性和学术命名规范相关。(iii) 背景不一致，存在前景后景标注不一致的问题。(iv) 结构器官重叠。各个结构器官之间存在重叠。(v) 数据重叠。一些 CT 扫描或者 MRI 图像在不同数据集中重叠，具有不同的标注。
其次，标签正交性。分割方法都是用 one-hot 标签 训练的，其先验偏差忽略了类之间的语义关系。

解决方法：1是采取经典的语义分割的方法，输入原图，输出对应所有类别的掩码预测，2是，模型输入增加一个提示向量，最终预测是固定的类别。
本研究采用第二种方法，传统其实仅输入one-hot向量，这里我们使用CLIP编码代之。

简而言之，本研究采用CLIP的零样本和少样本能力来解决心脏多数据集语义标签的先验偏差

方法上，本研究提出CLIP融合驱动的GFUNet
分 文本分支、视觉分支、掩码反向传播。
文本分支部分。有一系列预定义的提示模板，根据具体类别对应具体提示模板，比如对于CT的左心室，可以是“a computed tomography of Left Ventricle”。CLIP 嵌入编码由冻结的CLIP文本编码器得到，本文首先将 CLIP 嵌入编码（𝒘𝑘，对应图中的𝑄）和全局图像特征（𝒇 ，对应图中的𝐾, 𝑉 ）共同输入至 Transformer 解码器，以学习视觉到文本的上下文，这种提示模板范式称上下文感知提示。最后输出生成参数（𝜽𝑘），

视觉分支的核心是分割网络的编码器和解码器，这里采用GFUNet。视觉编码器提取的图像特征，具体经过了三个具有 1 × 1 × 1 内核的顺序卷积层，对应于视觉分支和文本分支的交界。视觉解码器每个类别的预测会经过和文本分支输出的参数的卷积计算，如式，最后经过sigmoid。

掩码反向传播部分。本研究使用 binary损失函数进行监督。掩盖了那些不包含在 𝒀 中的类别的损失项，并只将准确的监督信息反向传播以更新整个框架。掩码反向传播解决了部分标签问题中的标签不一致性。这是一种one versus all的训练模式。

之后是文本分支提到的上下文提示部分。z 是图像编码器最后一层的特征图，z bar是图像编码器得到的全局池化特征。视觉上下文感知提示 v 即为核心编码。
两种提示方法为图示和公式，主要区别在于，模型先提示（pre-model prompting）在推断期间需要额外的文本编码器前向传播，因为它的输入取决于图像，并且可学习的query也会增大参数量的开销。在模型后提示的情况下，还是使用预定义提示模板，且可以在训练后存储提取的文本特征，从而可以减少推断期间文本编码器带来的开销，更多论证和实验参考这篇论文。

这里使用MMWHS数据集，包含CT/MRI两种医学模态，其标签包含七个标签：

首先我们使用MMWHS做了一个提示模板的消融实验，七个类别，每个CT或者MRI类别对应自己的模板。文本提示编码模型包含one hot、BioBert、CLIP、Medical CLIP（这里使用的是PMC CLIP），以及使用CAP方式的Medical CLIP。提示的设计如表所示，结果也同预想，使用上下文感知提示的med CLIP得分最高。

在ACDC上的测试，以及集成多数据集的跨域实验。
跨域 cross-domain 指的是在 MMWHS 提前
训练的模型，在训练 ACDC 时初始化权重进行再训练得到的结构
不使用 CLIP提示驱动分割时，能根据其他数据集中学习的知识和得到的 ACDC 数据集的提升都非常有限。使用 CLIP提示驱动分割能十分有效地对集成泛化多数据集的训练。


