### Diffusion
DDPM实际是train一个noise predictor，实际是一个U-Net，这个UNet接受上一时刻的图像，和time embedding，预测这一步的ε，噪声，这个UNet是共享参数的。
### Transformer
1. 多头自注意力机制（Multi-Head Self-Attention）：这是 Transformer 的核心组件。多头自注意力机制允许模型在不同的表示子空间（representation subspaces）中学习输入序列的不同方面。具体来说，它将输入序列的每个单词表示分成多个“头”，每个头都有自己的权重矩阵。然后，每个头计算输入序列中所有单词之间的注意力分数，并将这些分数用于加权求和，以生成新的表示。最后，所有头的输出被拼接在一起，形成最终的输出表示。

	在这个机制中，表示子空间（representation subspaces）是指模型将输入序列的每个单词表示分成多个部分，每个部分都有自己的权重矩阵。这样做的目的是让模型能够在不同的子空间中学习输入序列的不同方面，从而捕捉更丰富的信息。
	
	为了更形象地解释这个概念，我们可以将多头自注意力机制想象成一个团队，团队中的每个成员都负责关注输入序列的某个特定方面。例如，一个成员可能关注语法结构，另一个成员可能关注词汇选择，还有一个成员可能关注情感信息等。这样，每个成员都能在自己的子空间中学习输入序列的特定信息，然后将这些信息整合起来，形成一个更全面、更丰富的表示。
	
	多头自注意力机制的优势在于，它允许模型同时关注输入序列的多个方面，从而更好地捕捉序列中的长距离依赖关系。这对于自然语言处理任务来说非常重要，因为语言中的信息往往是多层次、多方面的。通过使用多头自注意力机制，Transformer 模型能够在各个子空间中学习这些不同方面的信息，从而提高模型的性能。
    
2. 位置编码（Positional Encoding）：由于 Transformer 模型本身不具备捕捉序列中单词顺序的能力，因此需要引入位置编码来为输入序列中的每个单词添加位置信息。位置编码可以是固定的（如正弦和余弦函数）或可学习的。
	
      
	位置编码（Positional Encoding）在 Transformer 模型中起到了非常关键的作用。由于 Transformer 的自注意力机制本身是无序的，它无法捕捉输入序列中单词的顺序信息。然而，在自然语言处理（NLP）任务中，单词的顺序对于理解句子的含义至关重要。因此，我们需要引入位置编码来为输入序列中的每个单词添加位置信息。
	
	位置编码可以是固定的（如正弦和余弦函数）或可学习的。无论采用哪种方法，位置编码都会与输入序列的单词表示相加，从而将位置信息融入到模型中。这样，Transformer 模型就能够捕捉到输入序列中单词的顺序信息，并在处理 NLP 任务时考虑这些信息。
	
	与 Transformer 不同，循环神经网络（RNN）和长短时记忆网络（LSTM）天然地能够处理序列数据。这是因为 RNN 和 LSTM 的计算过程是按照时间步骤顺序进行的，每个时间步都会接收一个输入单词，并更新其隐藏状态。这种顺序计算过程使得 RNN 和 LSTM 能够捕捉输入序列中的顺序信息。然而，RNN 和 LSTM 的这种顺序计算特性也限制了它们的并行计算能力，导致训练速度较慢。
	
	相比之下，Transformer 通过引入位置编码来捕捉序列中的顺序信息，同时保持了自注意力机制的并行计算优势。这使得 Transformer 在处理 NLP 任务时既能考虑单词的顺序，又能实现高效的训练。因此，Transformer 在许多 NLP 任务中取得了比 RNN 和 LSTM 更好的性能。
	
1. 前馈神经网络（Feed-Forward Neural Network）：在多头自注意力机制之后，Transformer 使用前馈神经网络来进一步处理表示。这些网络通常包括两层全连接层和一个激活函数（如 ReLU）。
    
4. 残差连接（Residual Connection）和层归一化（Layer Normalization）：为了提高模型的训练稳定性，Transformer 使用残差连接和层归一化技术。残差连接允许模型在训练过程中更容易地学习恒等映射，而层归一化则有助于加速训练并提高模型的泛化能力。
    
5. 编码器-解码器结构（Encoder-Decoder Architecture）：Transformer 通常采用编码器-解码器结构，其中编码器负责将输入序列编码成固定长度的向量表示，而解码器则负责将这些表示解码成目标序列。编码器和解码器都由多层堆叠的 Transformer 层组成。

- 一个句子，patch encode/embed之后分成一个个向量或者说矩阵或者说tensor，然后矩阵线性变化成q, k, v三个不同矩阵（这些变换矩阵weighted在训练过程中需要学习），对每个向量的k，会和其他q点积，得到和其他向量的attention。除以$\sqrt{dim_{key}}$，这样梯度会更稳定。然后加上softmax操作，归一化分值使得全为正数且加和为1。softmax分值决定着在这个位置，每个词的表达程度。将softmax分值与value-vec按位相乘，保留关注词的value值，削弱非相关词的value值。将所有加权向量加和，产生该位置的self-attention的输出结果。

- 多头的作用（类似CNN的channel
	- 多头机制扩展了模型集中于不同位置的能力。
	- 多头机制赋予attention多种子表达方式。
	- multihead concat dot multiply weighted matrix -> one head size
	- 
![[Pasted image 20230623101333.png]]
- Decoder self-attention 层仅仅允许关注早于当前输出的位置。在softmax之前，通过遮挡未来位置（将它们设置为-inf）来实现。
- Encoder-Decoder Attention层工作方式跟multi-headed self-attention是一样的，除了一点，它从前层获取输出转成query矩阵，接收最后层编码器的key和value矩阵做key和value矩阵。
![[Pasted image 20230623111940.png]]
![[Pasted image 20230623112017.png]]

对每个Q，QK相乘，实际是算两个向量的相似度，或者说相关性。每个相关性矩阵再和K对应的V，即原token的一个变换进行相乘，算出Q在这个token下的注意力得分，最后将所有token的注意力得分相加得到注意力得分向量 (Z)，多头就是每个token生成多个qkv，最后得到多个z，然后对各个z做concat再乘学习的矩阵。最终得到这个Q对应的注意力得分矩阵。QKV都是源token的可学习的一个变换，或者说模型会调整这些qkv，已得到一个最佳的相关性语义网络，或者说这个[信号]拟合的分布。这是encoder做的事。
decoder就是在encoder的基础上，即encoder最终编码的KV给decoder，decoder为每个词做Q，**padding mask**输入序列进行对齐，pad非常大的负数(负无穷)。**Sequence mask**，每个状态只能观察到当前状态以及之前的token，后面的mask掉，预测下一个词，然后根据结构再进行预测。



### CNN
- dilated 卷积，卷积核扩张，中间一些部分抛空，参数量不变，但是能建立长依赖关系，或者说扩大感受野。深度卷积，设计为达到同样目的
- 可分离卷积（depthwise separable convolution）是一种卷积神经网络中的技术，它是由两个步骤组成的卷积操作：深度卷积（depthwise convolution）和逐点卷积（pointwise convolution）。
	
	深度卷积是一种只在每个输入通道上进行卷积的操作，对于每个输入通道，都有一个对应的卷积核进行卷积。它可以有效地减少模型参数的数量，从而降低了计算复杂度。具体来说，假设输入张量的形状为[N, H, W, C]，其中N为批次大小，H和W为张量的高度和宽度，C为通道数，则深度卷积的卷积核的形状为[K, K, C, 1]，其中K为卷积核的大小。
	
	逐点卷积是一种使用1x1的卷积核对深度卷积的结果进行卷积的操作。逐点卷积的作用是将深度卷积后的输出进行非线性变换，从而增加模型的表达能力。具体来说，逐点卷积的卷积核的形状为[1, 1, C, D]，其中D为输出通道数。

- CNN和Transformer之所以能够并行计算，是因为它们都具有一定的局部性和独立性。

- 在传统的神经网络中，每一层都会对输入进行一系列变换，例如卷积、全连接等操作，最终得到一组输出特征。如果网络的深度过大，信息就会在不断的变换中逐渐丢失，导致性能下降，同时也增加了梯度消失或梯度爆炸的风险。残差连接的引入可以有效地缓解这个问题。
	
	残差连接的实现方式是在每个卷积层或全连接层之后，添加一个跨层连接，将前一层的输出直接与当前层的输入相加。这样，当前层就能够直接学习输入和输出之间的残差，并将其加入到当前层的输出中，从而快速地向目标输出逼近。

- 线性层的运算是矩阵点积
	具体地，从卷积层到线性层的过程如下：

1. 扁平化操作：将最后一个卷积层输出的特征图扁平化为一个向量，即将(batch_size, channels, height, width)的输入数据转化为(batch_size, channels_height_width)的向量。这个操作可以使用PyTorch中的view()函数实现。
    
2. 全连接层：将扁平化后的特征向量作为输入，经过若干个全连接层（即线性层），进行特征分类。每个全连接层通常包含若干个神经元，可以将输入特征向量映射到新的特征空间中，从而生成更加有意义的特征表示。全连接层通常会使用激活函数进行非线性变换，例如ReLU、sigmoid等。
    
3. 输出层：最后一个全连接层的输出作为模型的预测结果，可以使用softmax函数将输出转化为概率分布，用于多类别分类任务，或者使用一个输出神经元表示回归问题的预测值。

==梯度消失和梯度爆炸==
-  梯度消失是指在反向传播过程中，由于层数太多，梯度在逐层反向传播中会不断地缩小，最终导致梯度接近于零，从而无法更新神经网络中的参数。这会导致深度神经网络的训练变得非常困难，甚至无法收敛。

	梯度爆炸则是指在反向传播过程中，由于层数太多，梯度在逐层反向传播中会不断地放大，最终导致梯度变得非常大，从而无法稳定地更新神经网络中的参数。这会导致深度神经网络的训练变得非常不稳定，甚至出现溢出等问题。
	
	这些问题通常出现在深度神经网络中，特别是在循环神经网络（Recurrent Neural Network）和深度卷积神经网络（Deep Convolutional Neural Network）中。这是因为这些网络通常有很多层，而每一层都会涉及到梯度的计算和传递。
	
	为了解决梯度消失和梯度爆炸问题，可以采用一些常见的技术，例如：
	
	1. 使用更好的激活函数，如ReLU、LeakyReLU等，可以有效地缓解梯度消失问题。
	    
	2. 使用批标准化（Batch Normalization）等技术，可以使每一层的输入都尽量接近于均值为0、方差为1的分布，从而加速网络的收敛。
	    
	3. 使用残差连接（Residual Connection）等技术，可以有效地解决梯度消失和梯度爆炸问题，同时提升网络的性能。
	    
	4. 使用梯度裁剪（Gradient Clipping）等技术，可以通过限制梯度的大小，避免梯度爆炸的问题。


### RNN（递归神经网络）：

RNN 是一种适用于序列数据的神经网络，其基本思想是在神经网络中引入循环连接，以允许信息在序列中传递。RNN 的数学表示如下：

假设我们有一个序列数据 $(x_1, x_2, \ldots, x_t)$，其中 $x_t$ 是序列的第 $t$ 个元素。RNN 的隐藏状态（hidden state） $h_t$ 和输出 $y_t$ 可以通过以下公式计算：

$$
h_t = \sigma(W_{hx}x_t + W_{hh}h_{t-1} + b_h)
$$

$$
y_t = \sigma(W_{yh}h_t + b_y)
$$

其中：
- $h_t$ 是时间步 $t$ 的隐藏状态。
- $x_t$ 是时间步 $t$ 的输入。
- $y_t$ 是时间步 $t$ 的输出。
- $W_{hx}$、$W_{hh}$、$W_{yh}$ 是权重矩阵。
- $b_h$、$b_y$ 是偏置项。
- $\sigma$ 是激活函数，通常使用 tanh 或 sigmoid。

RNN 的关键特点是它具有循环连接，使得当前时间步的隐藏状态 $h_t$ 受到前一个时间步的隐藏状态 $h_{t-1}$ 影响，因此能够捕捉序列数据中的时间依赖关系。然而，传统的 RNN 存在梯度消失和梯度爆炸等问题，限制了其在长序列中的性能。
![[Pasted image 20231106195546.png]]
###  LSTM（长短时记忆网络）：

LSTM 是一种改进的 RNN 变种，旨在解决传统 RNN 存在的梯度问题。LSTM 的数学表示如下：

LSTM 单元包括三个门（gate）：输入门（input gate）、遗忘门（forget gate）$f_t$、输出门（output gate）$o_t$。每个门都由一个 sigmoid 激活函数和一个乘法操作组成。LSTM 的隐藏状态 $h_t$ 和细胞状态（cell state） $c_t$ 可以通过以下公式计算：



==细胞状态和隐藏状态是横贯的，遗忘门、输入门、输出门和单位细胞状态更新值依赖于隐藏状态和每个输入，细胞状态是上一个细胞状态的遗忘和这次细胞状态更新值和输入的乘积的加权，隐藏状态是细胞状态做激活函数再乘输出门，也是真正的每个词输出，而非输入门。==


其中：
- $i_t$ 是输入门的输出。
- $f_t$ 是遗忘门的输出。
- $c_t$ 是细胞状态。
- $o_t$ 是输出门的输出。
- $W$ 和 $b$ 是权重矩阵和偏置项。
- $\sigma$ 是 sigmoid 激活函数，tanh 是双曲正切函数。

LSTM 的关键在于其门控机制，通过输入门、遗忘门和输出门，LSTM 能够有效地控制信息的流动，从而更好地处理长序列和解决梯度问题。
![[Pasted image 20231106195601.png]]
LSTM（长短时记忆网络）相对于传统的 RNN（递归神经网络）的改进主要体现在以下几个方面：

1. **解决梯度消失问题：** 传统的 RNN 在处理长序列时容易出现梯度消失或梯度爆炸的问题，导致难以训练深层网络。LSTM 使用了门控机制，特别是遗忘门（forget gate）来有效地控制信息的流动，避免了梯度消失问题，使得网络能够更好地处理长序列。

2. **长期记忆：** LSTM 的细胞状态（cell state）允许信息在长序列中持久传递。这意味着 LSTM 能够更好地捕捉长距离的时间依赖关系，对于需要记住长期信息的任务，LSTM 显著优于传统 RNN。

3. **门控机制：** LSTM 引入了三个门：输入门（input gate）、遗忘门（forget gate）、输出门（output gate）。这些门通过 sigmoid 激活函数和乘法操作来控制信息的输入、遗忘和输出，使 LSTM 能够学习什么信息应该存储、什么信息应该遗忘以及什么信息应该输出。这种门控机制增加了网络的灵活性，使其能够适应不同类型的序列数据。

4. **平滑梯度：** LSTM 的门控机制允许网络平滑地传播梯度，这使得训练更加稳定。这对于训练深层网络非常重要，因为它有助于避免梯度爆炸和梯度消失问题。

以下是LSTM中的三个门的具体作用：

1. 输入门（Input Gate）：控制输入向量对细胞状态的贡献。输入门根据当前的输入向量和隐藏状态，计算一个介于0和1之间的数值，表示当前输入向量对细胞状态的重要程度。
    
2. 遗忘门（Forget Gate）：控制上一个时间步骤的细胞状态对当前细胞状态的贡献。遗忘门根据上一个时间步骤的细胞状态和隐藏状态，计算一个介于0和1之间的数值，表示上一个时间步骤的细胞状态对当前细胞状态的重要程度。
    
3. 输出门（Output Gate）：控制当前细胞状态对隐藏状态的贡献。输出门根据当前的细胞状态和隐藏状态，计算一个介于0和1之间的数值，表示当前细胞状态对隐藏状态的重要程度。


总之，LSTM 相对于传统 RNN 的改进主要在于引入了门控机制，解决了梯度消失问题，增强了网络的长期记忆能力，并提高了训练的稳定性。这使得 LSTM 成为处理序列数据的更强大和有效的工具，特别是在自然语言处理（NLP）和时间序列分析等领域。

- 降采样有以下几个目的:
	1.降低显存和计算量，图小了占内存也就小了，运算量也少了。
	2.增大感受野，使同样$3\times3$的卷积能在更大的图像范围上进行特征提取。大感受野对分割任务很重要，小感受野是做不了多类分割的，而且分割出来的掩膜边界很粗糙！！
	3.多出几条不同程度下采样的分支，可以很方便进行多尺度特征的融合。多级语义融合会让分类很准。

- [一文理解机器学习中的极大似然估计(MLE) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/73380560)
	逻辑回归->极大似然函数->做KL散度得到优化目标->损失函数，即得到交叉熵


### Det
- YOLO将输入图像分成SxS个格子。每个格子输出B个bounding box（包含物体的矩形区域）信息，以及C个物体属于某种类别的概率信息。Bounding box信息包含5个数据值，分别是x,y,w,h,和confidence。其中x,y是指当前格子预测得到的物体的bounding box的中心位置的坐标。w,h是bounding box的宽度和高度。注意：实际训练过程中，w和h的值使用图像的宽度和高度进行归一化到[0,1]区间内；x，y是bounding box中心位置相对于当前格子位置的偏移值，并且被归一化到[0,1]
- confidence = P(object)$\times$IOU
- 因此，YOLO网络最终的全连接层的输出维度是 $S*S*(B*5 + C)$

### 计算图

在机器学习和深度学习领域，通常会使用两种不同类型的计算图，即静态图和动态图。Python 中的 Tensorflow 和 PyTorch 框架分别代表了这两种不同类型的计算图。

1. 静态图

静态图是一种先定义计算图结构，然后再将数据填充到图中执行的计算图模型。在静态图中，我们需要先使用框架提供的 API 定义计算图的结构，然后再通过会话（Session）将数据填充到计算图中执行。这种计算图可以被编译为高效的计算代码，并且可以在不同设备上执行，例如 CPU、GPU 和 TPU 等。

Tensorflow 是一种使用静态图的框架。在 Tensorflow 中，我们需要先定义计算图的结构，然后再在会话中执行计算图。例如，以下代码定义了一个简单的 Tensorflow 计算图，并执行了一次计算：

```python
import tensorflow as tf

# 定义计算图
a = tf.constant(1)
b = tf.constant(2)
c = a + b

# 创建会话并执行计算
with tf.Session() as sess:
    result = sess.run(c)
    print(result)
```

在这个例子中，我们首先使用 Tensorflow 的 API 定义了一个简单的计算图，其中包含常量 `a` 和 `b`，以及它们的和 `c`。然后，我们创建了一个会话，并使用 `sess.run()` 方法执行了计算图。最终，计算结果被保存在 `result` 变量中，并输出了结果 `3`。

2. 动态图

动态图是一种在运行时动态构建计算图的计算图模型。在动态图中，我们可以使用 Python 语言的控制流语句，例如 if 和 for 循环等，来构建计算图中的控制流。这种计算图可以更加灵活，且易于调试和修改，但是执行效率可能会比静态图低。

PyTorch 是一种使用动态图的框架。在 PyTorch 中，我们可以使用 Python 的控制流语句来构建计算图中的控制流。例如，以下代码定义了一个简单的 PyTorch 计算图，并执行了一次计算：

```python
import torch

# 定义计算图
a = torch.tensor(1)
b = torch.tensor(2)
c = a + b

# 执行计算
result = c.item()
print(result)
```

在这个例子中，我们首先使用 PyTorch 的 API 定义了一个简单的计算图，其中包含张量 `a` 和 `b`，以及它们的和 `c`。然后，我们直接执行了计算，将结果保存在 `result` 变量中，并输出了结果 `3`。

### 计算图的基本概念：

1. **节点（Node）：** 节点表示计算操作，如加法、乘法、卷积等。每个节点接收输入数据并产生输出数据。

2. **边（Edge）：** 边表示数据的流动方向，它连接了不同节点。数据从一个节点流向另一个节点。

3. **计算流程：** 计算图定义了神经网络中计算的流程。节点之间的连接关系和操作顺序决定了如何从输入数据生成输出数据。

#### 静态计算图（Static Computational Graph）：

在静态计算图中，整个计算图在模型定义阶段就已经构建好，并且在执行时保持不变。典型的静态计算图框架包括 TensorFlow 和 Theano。

**优点和高效性：**

- **计算优化：** 静态计算图允许框架在图构建时进行优化，例如常量折叠、梯度计算的自动求导等。这些优化可以提高计算效率。

- **分布式计算：** 静态计算图适用于分布式计算，因为整个图的结构在计算之前已经确定，可以更容易地进行分布式计算和部署。

**劣势和相对不灵活性：**

- **模型修改困难：** 一旦计算图构建完成，要修改模型结构通常需要重新构建整个计算图。这可能在某些情况下比较繁琐。

- **灵活性较低：** 静态计算图限制了模型的灵活性，难以实现一些需要在运行时动态调整的模型结构。

#### 动态计算图（Dynamic Computational Graph）：

在动态计算图中，计算图在执行时动态构建。每个操作都被视为一个计算图的节点，当数据通过网络流动时，计算图会动态生成。典型的动态计算图框架包括 PyTorch 和 Chainer。

**优点和灵活性：**

- **模型构建自由：** 动态计算图允许用户更自由地构建和修改模型，因为计算图是动态生成的，可以根据需要进行修改和调整。

- **易于调试：** 动态计算图可以更容易地进行调试和可视化，因为用户可以在执行过程中检查计算图的结构和数据流。

**劣势和效率较低：**

- **计算效率：** 动态计算图通常比静态计算图慢，因为它不允许框架在图构建时进行一些静态优化，例如常量折叠。

- **分布式计算：** 动态计算图在分布式计算方面可能存在一些挑战，因为计算图的结构在执行过程中不断变化。
#### 总结：

- **静态计算图**在计算效率和分布式计算方面具有优势，适用于固定结构的模型，如训练和推理阶段的部署。
  
- **动态计算图**在模型构建和调试方面更加灵活，适用于需要频繁修改和测试模型结构的场景，如深度学习研究和实验。

在实际应用中，有些深度学习框架提供了混合静态计算图和动态计算图的功能，允许用户根据需要选择合适的计算图构建方式，从而兼顾了高效性和灵活性。

动态图和静态图的数学描述涉及到计算图中节点和边的表示以及数据流动的方式。以下是它们的数学描述：

#### 静态图的数学描述：

在静态图中，通常使用符号或抽象表达来表示网络结构，其中节点表示操作，边表示数据的传递。考虑一个简单的静态图，其中有两个节点 A 和 B，它们表示两个矩阵相加的操作。我们可以用以下方式描述这个静态图：

1. 节点 A 表示操作：$A: C = X + Y$
   - 其中 $C$、$X$、$Y$ 是矩阵变量。
   - $+$ 表示矩阵相加操作。

2. 节点 B 表示操作：$B: Z = C \cdot W$
   - 其中 $Z$、$C$、$W$ 是矩阵变量。
   - $\cdot$ 表示矩阵相乘操作。

这些节点和边的关系构成了计算图，表示了数据从输入节点（$X$、$Y$）流经操作节点（$A$、$B$）到输出节点（$Z$）的计算过程。

#### 动态图的数学描述：

在动态图中，计算图是动态构建的，每个操作都被视为计算图的一个节点，操作的执行顺序决定了边的连接关系。考虑一个简单的动态图，其中有两个节点 A 和 B，它们表示两个数相加的操作。我们可以用以下方式描述这个动态图：

1. 节点 A 表示操作：$A: C = X + Y$
   - 其中 $C$、$X$、$Y$ 是标量或向量。

2. 节点 B 表示操作：$B: Z = C \cdot W$
   - 其中 $Z$、$C$、$W$ 是标量或向量。

在动态图中，这两个节点 A 和 B 的执行顺序由程序决定。例如，可以首先执行节点 A，计算出 $C$，然后再执行节点 B，计算出最终的输出 $Z$。

总之，静态图和动态图都使用数学表达来描述神经网络的结构和计算过程。静态图在模型定义时构建完整的计算图，而动态图在运行时根据操作的执行顺序动态构建计算图。这种不同方式反映了它们在模型定义和执行上的灵活性和效率的差异。




Leaky ReLU（Leaky Rectified Linear Unit）和ReLU（Rectified Linear Unit）都是常用的激活函数，它们的主要区别在于负数输入时的输出值不同。

ReLU函数在输入为正数时输出输入值本身，在输入为负数时输出0。而Leaky ReLU函数也在输入为正数时输出输入值本身，在输入为负数时则输出一个接近0的常数，通常为0.01或0.001。

这个小常数是为了避免ReLU函数在输入为负数时出现的“死区”现象，即输出值为0，导致神经元无法被激活。通过引入一个小常数，Leaky ReLU可以在输入为负数时也有一定的输出值，从而避免死区现象，保留一定的负数输入信息。

因此，相比于ReLU函数，Leaky ReLU在某些情况下可以更好地避免梯度消失（gradient vanishing）问题，同时也可以更好地处理负数输入。但是在其他情况下，ReLU函数可能会表现更好，因此根据具体的任务和数据集，选择使用哪种激活函数需要根据实际情况来决定。



- 对`[N, C, H, W]`，batch norm 按N也就是batch去正则化，layer norm按照channel也就是C去正则化