DDPM实际是train一个noise predictor，实际是一个U-Net，这个UNet接受上一时刻的图像，和time embedding，预测这一步的ε，噪声，这个UNet是共享参数的。

- transformer
1. 多头自注意力机制（Multi-Head Self-Attention）：这是 Transformer 的核心组件。多头自注意力机制允许模型在不同的表示子空间（representation subspaces）中学习输入序列的不同方面。具体来说，它将输入序列的每个单词表示分成多个“头”，每个头都有自己的权重矩阵。然后，每个头计算输入序列中所有单词之间的注意力分数，并将这些分数用于加权求和，以生成新的表示。最后，所有头的输出被拼接在一起，形成最终的输出表示。

	在这个机制中，表示子空间（representation subspaces）是指模型将输入序列的每个单词表示分成多个部分，每个部分都有自己的权重矩阵。这样做的目的是让模型能够在不同的子空间中学习输入序列的不同方面，从而捕捉更丰富的信息。
	
	为了更形象地解释这个概念，我们可以将多头自注意力机制想象成一个团队，团队中的每个成员都负责关注输入序列的某个特定方面。例如，一个成员可能关注语法结构，另一个成员可能关注词汇选择，还有一个成员可能关注情感信息等。这样，每个成员都能在自己的子空间中学习输入序列的特定信息，然后将这些信息整合起来，形成一个更全面、更丰富的表示。
	
	多头自注意力机制的优势在于，它允许模型同时关注输入序列的多个方面，从而更好地捕捉序列中的长距离依赖关系。这对于自然语言处理任务来说非常重要，因为语言中的信息往往是多层次、多方面的。通过使用多头自注意力机制，Transformer 模型能够在各个子空间中学习这些不同方面的信息，从而提高模型的性能。
    
2. 位置编码（Positional Encoding）：由于 Transformer 模型本身不具备捕捉序列中单词顺序的能力，因此需要引入位置编码来为输入序列中的每个单词添加位置信息。位置编码可以是固定的（如正弦和余弦函数）或可学习的。
	
      
	位置编码（Positional Encoding）在 Transformer 模型中起到了非常关键的作用。由于 Transformer 的自注意力机制本身是无序的，它无法捕捉输入序列中单词的顺序信息。然而，在自然语言处理（NLP）任务中，单词的顺序对于理解句子的含义至关重要。因此，我们需要引入位置编码来为输入序列中的每个单词添加位置信息。
	
	位置编码可以是固定的（如正弦和余弦函数）或可学习的。无论采用哪种方法，位置编码都会与输入序列的单词表示相加，从而将位置信息融入到模型中。这样，Transformer 模型就能够捕捉到输入序列中单词的顺序信息，并在处理 NLP 任务时考虑这些信息。
	
	与 Transformer 不同，循环神经网络（RNN）和长短时记忆网络（LSTM）天然地能够处理序列数据。这是因为 RNN 和 LSTM 的计算过程是按照时间步骤顺序进行的，每个时间步都会接收一个输入单词，并更新其隐藏状态。这种顺序计算过程使得 RNN 和 LSTM 能够捕捉输入序列中的顺序信息。然而，RNN 和 LSTM 的这种顺序计算特性也限制了它们的并行计算能力，导致训练速度较慢。
	
	相比之下，Transformer 通过引入位置编码来捕捉序列中的顺序信息，同时保持了自注意力机制的并行计算优势。这使得 Transformer 在处理 NLP 任务时既能考虑单词的顺序，又能实现高效的训练。因此，Transformer 在许多 NLP 任务中取得了比 RNN 和 LSTM 更好的性能。
	
1. 前馈神经网络（Feed-Forward Neural Network）：在多头自注意力机制之后，Transformer 使用前馈神经网络来进一步处理表示。这些网络通常包括两层全连接层和一个激活函数（如 ReLU）。
    
4. 残差连接（Residual Connection）和层归一化（Layer Normalization）：为了提高模型的训练稳定性，Transformer 使用残差连接和层归一化技术。残差连接允许模型在训练过程中更容易地学习恒等映射，而层归一化则有助于加速训练并提高模型的泛化能力。
    
5. 编码器-解码器结构（Encoder-Decoder Architecture）：Transformer 通常采用编码器-解码器结构，其中编码器负责将输入序列编码成固定长度的向量表示，而解码器则负责将这些表示解码成目标序列。编码器和解码器都由多层堆叠的 Transformer 层组成。

- RNN核心问题，无法并行计算，下一个状态依赖当前状态
- dilated 卷积，卷积核扩张，中间一些部分抛空，参数量不变，但是能建立长依赖关系，或者说扩大感受野。深度卷积，设计为达到同样目的
- 可分离卷积（depthwise separable convolution）是一种卷积神经网络中的技术，它是由两个步骤组成的卷积操作：深度卷积（depthwise convolution）和逐点卷积（pointwise convolution）。
	
	深度卷积是一种只在每个输入通道上进行卷积的操作，对于每个输入通道，都有一个对应的卷积核进行卷积。它可以有效地减少模型参数的数量，从而降低了计算复杂度。具体来说，假设输入张量的形状为[N, H, W, C]，其中N为批次大小，H和W为张量的高度和宽度，C为通道数，则深度卷积的卷积核的形状为[K, K, C, 1]，其中K为卷积核的大小。
	
	逐点卷积是一种使用1x1的卷积核对深度卷积的结果进行卷积的操作。逐点卷积的作用是将深度卷积后的输出进行非线性变换，从而增加模型的表达能力。具体来说，逐点卷积的卷积核的形状为[1, 1, C, D]，其中D为输出通道数。
- 
	self-attention  | $nd^2$ (n 句子长，d embedding dim) 
	cnn  | $HWk^2$ or $knd^2$ or $in*hw*out$
	rnn | $lnd^2$ 输入序列的长度为$n$，每个时间步的神经元数量为$d$，网络深度为$l$
	matrix multiply | $mnp$ -> opt $n^{2.3}$

- 对于长度为n的序列，Self-Attention的计算复杂度可以表示为$O(n^2)$, 这是因为对于每个元素，它需要与序列中的所有其他元素进行比较
- LSTM/Attention 的引入，加强了长距离语义建模的能力
- CNN和Transformer之所以能够并行计算，是因为它们都具有一定的局部性和独立性。
- 一个句子，patch encode/embed之后分成一个个向量或者说矩阵或者说tensor，然后矩阵线性变化成q, k, v三个不同矩阵（这些变换矩阵weighted在训练过程中需要学习），对每个向量的k，会和其他q点积，得到和其他向量的attention。除以$\sqrt{dim_{key}}$，这样梯度会更稳定。然后加上softmax操作，归一化分值使得全为正数且加和为1。softmax分值决定着在这个位置，每个词的表达程度。将softmax分值与value-vec按位相乘，保留关注词的value值，削弱非相关词的value值。将所有加权向量加和，产生该位置的self-attention的输出结果。
- 多头的作用（类似CNN的channel
	- 多头机制扩展了模型集中于不同位置的能力。
	- 多头机制赋予attention多种子表达方式。
	- multihead concat dot multiply weighted matrix -> one head size
	- 
![[Pasted image 20230623101333.png]]
- Decoder self-attention 层仅仅允许关注早于当前输出的位置。在softmax之前，通过遮挡未来位置（将它们设置为-inf）来实现。
- Encoder-Decoder Attention层工作方式跟multi-headed self-attention是一样的，除了一点，它从前层获取输出转成query矩阵，接收最后层编码器的key和value矩阵做key和value矩阵。


- 在传统的神经网络中，每一层都会对输入进行一系列变换，例如卷积、全连接等操作，最终得到一组输出特征。如果网络的深度过大，信息就会在不断的变换中逐渐丢失，导致性能下降，同时也增加了梯度消失或梯度爆炸的风险。残差连接的引入可以有效地缓解这个问题。
	
	残差连接的实现方式是在每个卷积层或全连接层之后，添加一个跨层连接，将前一层的输出直接与当前层的输入相加。这样，当前层就能够直接学习输入和输出之间的残差，并将其加入到当前层的输出中，从而快速地向目标输出逼近。

- 线性层的运算是矩阵点积
	具体地，从卷积层到线性层的过程如下：

1. 扁平化操作：将最后一个卷积层输出的特征图扁平化为一个向量，即将(batch_size, channels, height, width)的输入数据转化为(batch_size, channels_height_width)的向量。这个操作可以使用PyTorch中的view()函数实现。
    
2. 全连接层：将扁平化后的特征向量作为输入，经过若干个全连接层（即线性层），进行特征分类。每个全连接层通常包含若干个神经元，可以将输入特征向量映射到新的特征空间中，从而生成更加有意义的特征表示。全连接层通常会使用激活函数进行非线性变换，例如ReLU、sigmoid等。
    
3. 输出层：最后一个全连接层的输出作为模型的预测结果，可以使用softmax函数将输出转化为概率分布，用于多类别分类任务，或者使用一个输出神经元表示回归问题的预测值。

-  梯度消失是指在反向传播过程中，由于层数太多，梯度在逐层反向传播中会不断地缩小，最终导致梯度接近于零，从而无法更新神经网络中的参数。这会导致深度神经网络的训练变得非常困难，甚至无法收敛。

	梯度爆炸则是指在反向传播过程中，由于层数太多，梯度在逐层反向传播中会不断地放大，最终导致梯度变得非常大，从而无法稳定地更新神经网络中的参数。这会导致深度神经网络的训练变得非常不稳定，甚至出现溢出等问题。
	
	这些问题通常出现在深度神经网络中，特别是在循环神经网络（Recurrent Neural Network）和深度卷积神经网络（Deep Convolutional Neural Network）中。这是因为这些网络通常有很多层，而每一层都会涉及到梯度的计算和传递。
	
	为了解决梯度消失和梯度爆炸问题，可以采用一些常见的技术，例如：
	
	1. 使用更好的激活函数，如ReLU、LeakyReLU等，可以有效地缓解梯度消失问题。
	    
	2. 使用批标准化（Batch Normalization）等技术，可以使每一层的输入都尽量接近于均值为0、方差为1的分布，从而加速网络的收敛。
	    
	3. 使用残差连接（Residual Connection）等技术，可以有效地解决梯度消失和梯度爆炸问题，同时提升网络的性能。
	    
	4. 使用梯度裁剪（Gradient Clipping）等技术，可以通过限制梯度的大小，避免梯度爆炸的问题。

- 
![[Pasted image 20230623111940.png]]
![[Pasted image 20230623112017.png]]


- 反向传播：反向传播是指根据损失函数计算每个参数对损失函数的梯度的过程。


- LSTM相对于传统的RNN，引入了三个门（输入门、遗忘门和输出门），以控制信息的流动和更新。具体来说，LSTM的每个时间步骤都会接收一个输入向量、一个隐藏状态向量和一个细胞状态向量，然后通过一系列门的控制，将当前的输入信息和前面的历史信息进行融合，从而更新隐藏状态和细胞状态。

以下是LSTM中的三个门的具体作用：

1. 输入门（Input Gate）：控制输入向量对细胞状态的贡献。输入门根据当前的输入向量和隐藏状态，计算一个介于0和1之间的数值，表示当前输入向量对细胞状态的重要程度。
    
2. 遗忘门（Forget Gate）：控制上一个时间步骤的细胞状态对当前细胞状态的贡献。遗忘门根据上一个时间步骤的细胞状态和隐藏状态，计算一个介于0和1之间的数值，表示上一个时间步骤的细胞状态对当前细胞状态的重要程度。
    
3. 输出门（Output Gate）：控制当前细胞状态对隐藏状态的贡献。输出门根据当前的细胞状态和隐藏状态，计算一个介于0和1之间的数值，表示当前细胞状态对隐藏状态的重要程度。


- 降采样有以下几个目的:
	1.降低显存和计算量，图小了占内存也就小了，运算量也少了。
	2.增大感受野，使同样$3\times3$的卷积能在更大的图像范围上进行特征提取。大感受野对分割任务很重要，小感受野是做不了多类分割的，而且分割出来的掩膜边界很粗糙！！
	3.多出几条不同程度下采样的分支，可以很方便进行多尺度特征的融合。多级语义融合会让分类很准。


- [一文理解机器学习中的极大似然估计(MLE) - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/73380560)
	逻辑回归->极大似然函数->做KL散度得到优化目标->损失函数，即得到交叉熵


YOLO
- YOLO将输入图像分成SxS个格子。每个格子输出B个bounding box（包含物体的矩形区域）信息，以及C个物体属于某种类别的概率信息。Bounding box信息包含5个数据值，分别是x,y,w,h,和confidence。其中x,y是指当前格子预测得到的物体的bounding box的中心位置的坐标。w,h是bounding box的宽度和高度。注意：实际训练过程中，w和h的值使用图像的宽度和高度进行归一化到[0,1]区间内；x，y是bounding box中心位置相对于当前格子位置的偏移值，并且被归一化到[0,1]
- confidence = P(object)$\times$IOU
- 因此，YOLO网络最终的全连接层的输出维度是 $S*S*(B*5 + C)$


---
在机器学习和深度学习领域，通常会使用两种不同类型的计算图，即静态图和动态图。Python 中的 Tensorflow 和 PyTorch 框架分别代表了这两种不同类型的计算图。

1. 静态图

静态图是一种先定义计算图结构，然后再将数据填充到图中执行的计算图模型。在静态图中，我们需要先使用框架提供的 API 定义计算图的结构，然后再通过会话（Session）将数据填充到计算图中执行。这种计算图可以被编译为高效的计算代码，并且可以在不同设备上执行，例如 CPU、GPU 和 TPU 等。

Tensorflow 是一种使用静态图的框架。在 Tensorflow 中，我们需要先定义计算图的结构，然后再在会话中执行计算图。例如，以下代码定义了一个简单的 Tensorflow 计算图，并执行了一次计算：

```python
import tensorflow as tf

# 定义计算图
a = tf.constant(1)
b = tf.constant(2)
c = a + b

# 创建会话并执行计算
with tf.Session() as sess:
    result = sess.run(c)
    print(result)
```

在这个例子中，我们首先使用 Tensorflow 的 API 定义了一个简单的计算图，其中包含常量 `a` 和 `b`，以及它们的和 `c`。然后，我们创建了一个会话，并使用 `sess.run()` 方法执行了计算图。最终，计算结果被保存在 `result` 变量中，并输出了结果 `3`。

2. 动态图

动态图是一种在运行时动态构建计算图的计算图模型。在动态图中，我们可以使用 Python 语言的控制流语句，例如 if 和 for 循环等，来构建计算图中的控制流。这种计算图可以更加灵活，且易于调试和修改，但是执行效率可能会比静态图低。

PyTorch 是一种使用动态图的框架。在 PyTorch 中，我们可以使用 Python 的控制流语句来构建计算图中的控制流。例如，以下代码定义了一个简单的 PyTorch 计算图，并执行了一次计算：

```python
import torch

# 定义计算图
a = torch.tensor(1)
b = torch.tensor(2)
c = a + b

# 执行计算
result = c.item()
print(result)
```

在这个例子中，我们首先使用 PyTorch 的 API 定义了一个简单的计算图，其中包含张量 `a` 和 `b`，以及它们的和 `c`。然后，我们直接执行了计算，将结果保存在 `result` 变量中，并输出了结果 `3`。

总之，Python 中的 Tensorflow 和 PyTorch 框架分别代表了静态图和动态图这两种不同类型的计算图。静态图在定义计算图结构后可以被编译为高效的计算代码，并可以在不同设备上执行。动态图可以更加灵活，易于调试和修改，但是执行效率可能会比静态图低。

---
Leaky ReLU（Leaky Rectified Linear Unit）和ReLU（Rectified Linear Unit）都是常用的激活函数，它们的主要区别在于负数输入时的输出值不同。

ReLU函数在输入为正数时输出输入值本身，在输入为负数时输出0。而Leaky ReLU函数也在输入为正数时输出输入值本身，在输入为负数时则输出一个小于0的常数，通常为0.01或0.001。

这个小常数是为了避免ReLU函数在输入为负数时出现的“死区”现象，即输出值为0，导致神经元无法被激活。通过引入一个小常数，Leaky ReLU可以在输入为负数时也有一定的输出值，从而避免死区现象，保留一定的负数输入信息。

因此，相比于ReLU函数，Leaky ReLU在某些情况下可以更好地避免梯度消失（gradient vanishing）问题，同时也可以更好地处理负数输入。但是在其他情况下，ReLU函数可能会表现更好，因此根据具体的任务和数据集，选择使用哪种激活函数需要根据实际情况来决定。