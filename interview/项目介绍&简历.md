## 小型web框架
主要借鉴Gin
- `net/http`提供了基础的Web功能，即监听端口，映射静态路由，解析HTTP报文
- 整体的这个处理请求给出响应的主体，定为Engine这个struct，处理用户的GET的行为就是这个Engine的方法，监听端口并运行
- 对客户端的请求，服务端都得给出一个handler方法，封装handler的端口，自定义一个Context封装Request和ResponceWriter，Context也对
- 将router和handler的映射从分离出来，并增加routerGroup，对不同组的group采用不同的中间件，以及实现动态路由，动态路由具体采用Trie树实现，Trie树更具体是用指针数组实现的
- 中间件的实现，具体是在context下面增加middleware的handler，再增加use方法，服务端执行中间件的时候，调用这个use就行
- 还有就是一些细节，比如logger，template渲染模板

## 分布式缓存
主要借鉴groupcache
- 核心数据结构Group负责与用户的交互，并且控制缓存值存储和获取的流程，可以认为是一个缓存的命名空间。缓存不存在时，需要在本地回调时，调用回调函数，这里抽象出接口getter，本地不存在就从远程获取节点，具体采用http服务
- 手动实现LRU内存淘汰机制，具体由map和双向链表实现，淘汰队首，插入和访问时放至队尾，抽象byteView表示缓存值，之后对cache实现的修改操作进行加锁
- 简单的哈希映射没有考虑节点数量变化的场景。当节点数量变化时，几乎缓存值对应的节点都发生了改变，即几乎所有的缓存值都失效了，造成瞬时DB请求量大，即缓存雪崩。
- 引入一致性哈希。映射空间是固定的2^32，形成一个环。首先节点都放置在环上，key映射在环上的某个值，顺时针寻找第一个节点，就是其对应节点
- 数据倾斜，即节点分布比较集中，这时将映射关系从真实节点改到虚拟节点即可
- 数据击穿，相同一个端口发送大量请求，主要使用waitgroup解决，具体需要抽象出singleflight
- 缓存穿透：查询一个不存在的数据


## **自我介绍**

我研究生的课题主要是利用深度学习和计算机视觉的方法去解决医学图像领域的分割和域适应的问题。
研究生做的有一个课题是关于FFT在深度学习和医学图像分割中的应用，这个课题总结发了一篇期刊文章。
之后有两段实习，一是在美的ai创新中心，主要做的是调研和设计解决部分标注问题。二是在透彻未来，我主要参与大规模预训练模型的训练和分割监督网络的训练，还有去生成热力图，最后是一段模型部署的经历。
最后我平时也会看一些计算机包括开发的各种的东西。

具体来说我会利用ViT的位置编码策略先给图像分块以及各个块全局位置信息，之后对图的特征进行经过全局频域块，这个全局频域块实际是对图像进行FFT再乘一个可学习的矩阵，以学习这个图像特征，再iFFT，再用卷积下采样。循环数个步骤已完成编码学习，之后decoder主要采取resnet的策略。
## 频域分割网络

- encoder， decoder的UNet的整体结构，其实和FPN的思想几乎说一样
Encoder部分：
- 图片采取ViT的分块加位置编码，embedding化
- 交替使用两个block
- 一是全局频域block，对feature map进行FFT，对频域图进行和一个有参数量的矩阵做乘法，再iFFT，LN
- 二是进行卷积下采样的block
- 进行5次
- 为什么有效。创新点？
	1. 卷积定理，两个函数或者信号在时域中的卷积等价于频域中的相乘（逐点相乘）
	2. 连续傅里叶到离散傅里叶，以便计算机的离散处理
	3. 快速傅里叶，利用傅里叶变换后频域信息的对称和周期性，从$O(n^2)$到$O(nlogn)$
	4. 频域信号更能捕捉MRI图像中的各频信息，因为许多医学图像都是有清晰的纹理和各个结构的相对位置信息。深度学习如何学习图像特征，都会做数据增强，CNN，窗口分块平移学习，ViT，图像分块token化全局相关性学习，基于FFT的，图像分块token化全局频域学习。
- ==为什么需要位置编码？==
	(转化后的频域波之间没有位置关系，研究数学性质时可以不关注，但我们进行深度学习特征关系会他们的位置关系)
	我需要embedding化图像，因为CHW的图像要转化为NQ二维的，使用2DFFT，这要求我们对降维的图像位置编码，其实不用位置编码也可以，因为频域本身有位置信息，但我这里加了。因为3DFFT复杂度会更大，而且图像本质是二维性质的。
- 如何从时域转化到频域？
	傅里叶级数就是任何周期函数能转化为正弦余弦加权和，连续形式的傅里叶变换其实是傅里叶级数（Fourier series）的推广，用欧拉公式。

| arch | Param | FLOPS |
|:-:|:-:|:-:|
|self-attention| $nd^2$ (n 句子长，d embedding dim) $O\left(2 D_k N D_x+D_v N D_x+N^2 D_k+1+D_x N^2\right)=O\left(N^2\right)$ | $4d^2$ ($3d^2$是qkv计算) |
|cnn | $k^2*C_{out}*C_{in}$ (bias+1) | $k^2*C_{out}*C_{in}*WH$|
| rnn | $lnd^2$ (网络深度为$l$)||
|matrix multiply | $mn+np$ |$mnp$ -> opt $n^{2.3}$|
| Global Filter | $HWC_{in}$ | $HWC_{in} logHW+ HWC_{in}$  |

### 每个像素的变换：

对于一个二维图像，FFT涉及对每个像素进行傅里叶变换。每个像素的值表示图像中对应位置的亮度或颜色，FFT之后的信号更关注波的性质。傅里叶变换将这些像素值根据DFT的公式转换为复数形式（这里也涉及坐标转换），根据复数形式的像素值可计算幅值和相位。
经过iDFT变回时域，可以证明是一一对应的转换，进行CNN下采样。

### 得到的值的意义以及可视化：

1. **幅值：** 表示在频率域中每个频率分量的强度。高幅值对应于图像中的边缘和细节，低幅值对应于平滑的区域。

2. **相位：** 表示在频率域中每个频率分量的相对位置。相位信息对于一些图像处理任务，如图像复原和合成，非常重要。

可以对幅值图和相位图进行可视化

通过对图像进行FFT，我们可以分析其频率特征，进行频域滤波，提取特征，进行图像压缩等操作。FFT在图像处理中具有广泛的应用，特别是在计算机视觉和图像分析领域。
### 一般图像的FFT过程：

1. **选择图像：** 选择一幅灰度图像，这通常是一个二维矩阵，其中每个元素代表图像中对应位置的像素值。
2. **像素值归一化：** 将像素值从0到255归一化到-1到1之间。这是因为FFT期望输入在一定范围内，而不是在0到255之间。
3. **进行FFT：** 对图像矩阵执行二维FFT。这会将图像从空间域转换到频率域。FFT的结果是一个包含复数值的矩阵，其中每个元素对应频率域中的一个点。
4. **频率域中心化：** 对FFT结果进行中心化，将低频分量移到频谱的中心。这可以通过调用`fftshift`函数实现。
5. **取模（Magnitude）：** 取频率域矩阵的模，即复数的幅值。这反映了每个频率分量在原始图像中的贡献。
6. **取相位（Phase）：** 取频率域矩阵的相位，即复数的角度。这反映了每个频率分量在图像中的位置。

### FFT的意义
图像做FFT（快速傅里叶变换）有很多意义，其中一些主要的包括：
1. **频域分析：** FFT将图像从空间域转换到频率域。这使得我们可以分析图像中不同频率的成分。在频率域中，==**高频分量对应图像的细节和边缘，而低频分量对应图像的整体结构**==。通过分析频域信息，我们可以更好地理解图像的特征。
    
2. **滤波：** 在频域中，我们可以对图像进行滤波，以增强或减弱特定频率的成分。这可以用于去除图像中的噪声、强调特定细节，或者执行其他图像处理任务。例如，通过去除高频成分，我们可以实现模糊效果。
    
3. **压缩：** 在频域中，图像的能量通常集中在较低的频率上。这使得我们可以通过保留较低频率的信息，而丢弃高频率的信息来实现图像压缩。这是JPEG等压缩算法的基本原理之一。
    
4. **特征提取：** FFT可以用于提取图像中的特定频率的特征。这在图像识别、图像分割和其他计算机视觉任务中是有用的。
    
5. **图像处理和编辑：** 在频域中编辑图像可以导致有趣的效果。例如，通过在频域中对图像施加相位变化，我们可以实现图像的位移效果。

傅里叶变换有两个部分：实部和虚部。==实部==表示图像中的==余弦分量==，==虚部==表示图像中的==正弦分量==。而傅里叶变换的==幅值和相位==分别表示了每个频率分量的强度和相位。

对于图像中的每个像素，傅里叶变换都会计算对应频率的复数值，这样就得到了图像在频域中的表示。在计算机图像处理中，通常我们关注的是频域中的低频和高频成分，以便进行滤波、特征提取等操作。
loss =  dice loss + CE

CE对图像是逐像素的类别预测差异运算 -y(class)logp





## CLIP driven
尝试使用CLIP这种大型预训练视觉语言模型
CLIP预训练出text encoder和image encoder
- 传统医学图像语义分割都是假设各个标签是正交的关系，往往最后可用one hot编码表示，但标签实际上是有语义之间的联系，这个假设是和真实分布有偏差的。一般基于Dice loss和CE的语义分割是不大好学习这个偏差以及标签语义之间的相关性的。
- CLIP融合驱动能达到一种软标签或者说提供更多语义信息的效果
- 对每个标签，输入包括预定义prompt，比如一张什么器官的医学图像，还有一张对应的图像，这里就是保证输入的是图文的正样本对，prompt在CLIP的text encoder进行推理得到embedding，这个文本编码器是frozen的，图片经过需要训练的encoder得到编码，两个embedding进行concat，经过MLP得到参数，visual embedding经过它的decoder得到的feature map会和这个参数做卷积，和gt做损失，再反向传播。
- 这里用B dice loss，b ce，会实现根据对比空间对像素的拉取的效果

先验处理标签对齐问题
- text prompt 部分其实是作为一种先验，参与训练的是在text encoder推理出来的embedding，所以内存损耗其实很小。怎么跟标签进行对其，这里我采取的方法是，预先存取一个字典，数据集对应哪几个类/标签，网络最后decoder出来的feature的channel维的各个类/标签最后进行损失，这里都是binary的损失，同binary化的标签做损失
- 实际推理仍然是原图推理出分割预测图，这里也需要提前设置这个字典

这里的loss是什么？
BDICE + BCE
多分类的dice也是根据Binary Dice得到的

### CLIP讲解

CLIP采用对比学习的策略
**对比学习**的目标是学习一个编码器，此编码器**对同类数据进行相似的编码，并使不同类的数据的编码结果尽可能的不同**
进一步来说：
- **目标**：**给定锚点，通过空间变换，使得锚点与正样本间距离尽可能小，与负样本距离尽可能大**
- **丈量二者距离**：欧几里得距离，余弦相似度，马氏距离（没人试过，但原理是一样的）
根据这个可以得到类似聚类的一个损失

我们实际都是面对的概率模型，这就要求我们从互信息的角度来解决对比学习的问题：
![[Pasted image 20240103185905.png]]
==图像和文本经过encoder得到feature，feature点乘学习的矩阵投影到embedding，embedding之间做余弦相似度计算得到$N\times N$的相似度矩阵，最后行对列，列对行做交叉熵，其平均就是目标损失。==
## YOLOv8部署和加速
参与包括 YOLOv8，EfficientNet 和 DeepLab 多个视觉模型的边端部署和加速，设计 ONNX, TensorRT 推理模型转换和 CUDA 加速，以及 C++ 服务（采取json的TCP通信）

你做的部分？时间能做到多少优化

官方给出：

|Model|size  <br>(pixels)|mAPbox  <br>50-95|mAPmask  <br>50-95|Speed  <br>CPU ONNX  <br>(ms)|Speed  <br>A100 TensorRT  <br>(ms)|params  <br>(M)|FLOPs  <br>(B)|
|---|---|---|---|---|---|---|---|
|YOLOv8l-seg|640|52.3|42.6|572.4|2.79|46.0|220.5|

实际测试：
  
| | | |men推理前|mem推理时|MEM|GPUMEN|CPU|GPU|
|---|---|---|---|---|---|---|---|---|---|
|yolov8n|FP16|9ms|2.4G|3.3G|474M|653M|>90%|50.40%|
|yolov8s||14ms|2.4G|3.3G|474M|677M|>100%|80.00%|
|yolov8m||28ms|2.4G|3.3G|474M|716M|>90%|99.00%|
|yolov8l||40ms|2.5G|3.5G|472M|762M|>90%|99.00%|
|yolov8x||65ms|2.5G|3.5G|472M|821M|>60%|99.60%|

| |接收到解析完成(ms)|推理时间(ms)|后处理到发送完成(ms)|
|---|---|---|---|
|1|173|8718|32|
|2|53|54|31|
|3|50|54|27|
|4|62|54|22|
|5|57|54|23|
  
| |1|2|3|4| |
|---|---|---|---|---|---|
|n|9|13|22|27|5-8分钟|
|s|14|22|36|45|-|
|m|28|58|82|100|-|
|l|40|79|115|130 x 3/95|加载非常慢|
|x|64|146|150|||

| |1|2|3|4|
|---|---|---|---|---|
|n|9|13|22|27|
|s|14|22|36|45|
|m|28|58|82|100|
|l|40|79|115|122|
|x|64|146|150||

![[Pasted image 20240103153739.png]]


1. 模型轻量化，量化剪枝蒸馏
2. CUDA加速。C++工程，重写？
3. 通信服务

ViT basic large
ViT分类模型，怎么弄
说说各layer的特征交互情况
mask attention
全局频域中的频域怎么体现
loss怎么设计 dice loss, CE, BCE, Binary dice loss

## Mask2former

**单尺度的可变性注意力机制**
对于一般的attention，query与key的每个值都要计算注意力，这样的问题就是耗显存；另外，对图像来说，假设其中有一个目标，一般只有离图像比较近的像素才有用，离比较远的像素，对目标的贡献很少，甚至还有负向的干扰。
![[Pasted image 20240103155635.png]]
Defromable attention的设计思路就是query不与全局的key进行计算，而是至于其周围的key进行计算。至于这个周围要选哪几个位置，就类似DCN，让模型自己去学。


**多尺度的可变性注意力机制**
多尺度即类似fpn，提取不同尺度的特征，但由于特征的尺寸不一样，需要将不同尺度的特征连接起来

**cross-attention and self-attention**
输入左下角和右下角attention layer的三个箭头是从一个地方分出来的，说明 $Q,K,V$ 三个矩阵都是从输入矩阵$X$变化来的。那为什么cross-attention要加一个cross？没错，因为**这三个矩阵$Q,K,V$ 要从不同的输入矩阵变化来**。
### 相同点：

1. **机制**：两者都使用了点积注意力机制（scaled dot-product attention）来计算注意力权重。
2. **参数**：无论是自注意力还是交叉注意力，它们都有查询（Query）、键（Key）和值（Value）的概念。
3. **计算**：两者都使用查询和键之间的点积，然后应用softmax函数来计算注意力权重。
4. **输出**：在计算完注意力权重后，两者都将这些权重应用于值来得到输出。
5. **可变性**：两者都可以通过掩码（masking）来控制某些位置不被其他位置关注。
### 不同点：

**Self Attention:** 查询、键和值都来自同一个输入序列。这使得模型能够关注输入序列中的其他部分以产生一个位置的输出。主要目的是捕捉输入序列内部的依赖关系。在Transformer的编码器（Encoder）和解码器（Decoder）的每一层都有自注意力。它允许输入序列的每个部分关注序列中的其他部分。

**Cross Attention:** Q查询来自一个输入序列，而K键和V值来自另一个输入序列。这在诸如序列到序列模型（如机器翻译）中很常见，==其中一个序列需要“关注”另一个序列==。目的是使一个序列能够关注另一个不同的序列。主要出现在Transformer的解码器。它允许解码器关注编码器的输出，这在机器翻译等任务中尤为重要。

总的来说，自注意力和交叉注意力都是基于相同的核心机制，但它们的应用和目的有所不同。自注意力旨在处理单一序列内部的关系，而交叉注意力则旨在处理两个不同序列之间的关系。

**类别和mask分开预测**
原本的语义分割per-pixel classification，具体我们对最后的feature做softmax，再做argmax
maskformer采取分离方法，binary得预测多少个目标mask，原文称作query，和所有的class进行匹配，这里使用匈牙利匹配算法。
采用这种query的方式，既可以做instance也可以做语义分割，全景分割也是实例和语义的结合

## DINOv2

方法大致同v1
Self-distillation
自蒸馏创造了一个教师和一个学生网络。 这两个网络都具有完全相同的模型架构

一张图片被裁剪成两种尺寸，然后输入学生和教师网络。 对教师的输出应用居中操作，并且两个输出都通过 softmax 层归一化整理。
两个 softmax 输出都传递到损失函数中，使用随机梯度下降 (SGD) 执行反向传播。在这里的反向传播是通过学生网络执行的，这时教师的权重尚未更新的原因。 为了更新教师模型，DINO 对学生权重使用指数移动平均 (EMA)，将学生网络的模型参数传输到教师网络

![[Pasted image 20240103172245.png]]
![[Pasted image 20240103172211.png]]
Intra-image self-supervised training, Discriminative self-supervised learning, Scaling self-supervised pretraining, Automatic data curation

**Data Processing**
Deduplication, Self-supervised image retrieval

**Efficient implementation**
## MarioGPT

a distilled, lightweight version of GPT2

encoding slices of Mario levels as strings, we can fine-tune this distilled version of GPT2 on predicting next tokens in Mario levels

To generate levels, we concatenate a window of previous 50 columns into a single vector and feed them into MarioGPT.

Prompting details: Prompts are encoded through BERT, a frozen pre-trained language model. Prompts are passed through the frozen language model and the hidden states from the forward pass are averaged into a single vector. This average hidden state is then used in the cross attention layers of the GPT2 architecture in combination with the actual level sequence being passed into the model.

Procedural Content Generation, Open-Endedness, Playability, Novelty


## SAM

- image encoder, prompt encoder(dense sparse)将图像和提示（mask, text_CLIP, box, point）映射特征空间，训练对齐再decoder得到掩码
- promptable segmentation
- data engine SA-1B的dataset，1B图像和10B的mask
- SAM目前生成的mask都是无标签的（mask, IOU），对于需要类别的mask，可以考虑增加head，监督训练类别。可以参考SSA这个项目，利用COCO和ADE20K生成一个类别标签，再结合Open-vocabulary生成多个类别标签，最终过滤得到多个可能的标签。


## YOLO, Faster RCNN, DeTR

### Faster RCNN
RPN生成区域提议，即包含目标的潜在边界框。它使用不同尺度和长宽比的锚框来提出区域。

使用RoI特征进行目标分类和边界框回归。采用softmax层进行分类，确定提议区域内对象的类别，并采用回归器调整边界框坐标以更好地适应目标。

### YOLOv5
==FPN== 跟UNet可以说几乎一回事 
多尺度训练/预测
==PANet== 式的增强模式，类似于UNet架构结合深度监督的分割的学习范式，都是多尺度金字塔的采样学习加各层次融合、跳跃链接和监督。这里是用作实例分割

一般都是BOX branch，包括 bbox confidence（4+1）和class（+80）box/anchor数目（plus 3），预测mask的branch

anchor是根据数据集进行聚类得到的框，一个grid对应多个anchor，anchor based的目标检测回归的box都是根据anchor和grid得到的

模型的任务就是基于anchor尽量得到接近gt的box

==正负样本的匹配（训练阶段，计算Loss前）==

![[Pasted image 20240115000733.png]]

1. **Anchor Boxes的生成：** 在一些目标检测方法中，首先会定义一组预定义的锚框（Anchor Boxes）或候选框，这些框具有多个尺度和长宽比。这些锚框将用于生成候选目标区域。
    
2. **正样本匹配：** 对于每个真实目标，通过计算其与所有锚框的IoU（交并比），选择与之最匹配的锚框/grid作为正样本。通常，如果IoU大于某个阈值（通常为0.5），则将该锚框标记为正样本。这表示该锚框负责预测该目标的位置和类别。之后进行正样本的投影扩展。
    
3. **负样本匹配：** 除了正样本，还需要确定负样本，即那些不与任何真实目标相匹配的锚框。一种常见的策略是选择IoU小于一定阈值（例如0.3）的锚框作为负样本。这有助于模型学习如何将负样本正确排除。
    
4. **样本不平衡处理：** 由于负样本通常远多于正样本，可能导致样本不平衡问题。为了解决这个问题，可以使用一些权重调整或在线难例挖掘策略，使得正负样本的贡献更加平衡。
    
5. **多级别匹配：** 对于一些多阶段的目标检测算法，如Faster R-CNN，引入了多级别的样本匹配，分别在RPN（Region Proposal Network）和目标检测阶段进行。这有助于更好地处理不同任务的样本匹配。

正负样本匹配不同YOLO版本采取不同策略，简言之就是最后预测出的anchor_size(4+1+cls)的每个anchor，哪些是与gt匹配，哪些不匹配。

For each 计算IoU，根据阈值决定正负；YOLO v5之后
TaskAlignedAssigner 的匹配策略简单总结为： **根据分类与回归的分数加权的分数选择正样本**。

- 一个 GT Bbox 能够匹配多个 Prior/anchor
    
- 一个 GT Bbox 和一个Prior 匹配时，能分配 1-3 个正样本
    
- 以上策略能**适度缓解目标检测中常见的==正负样本不均衡==问题**。

==Loss==

class BCE, objectness BCE, Location CIoU
CIOU引入了对边界框形状和位置的修正，使得它相对于IoU更加健壮。


==NMS==代表非极大值抑制（Non-Maximum Suppression）**后处理阶段**，是在目标检测任务中常用的一种技术。其主要目的是==减少冗余==的边界框，保留最相关的边界框，以防止在同一目标上生成多个相似的边界框。因为之前是For each匹配，会出现多个anchor对应一个gt的情况

0、建造一个存放待处理候选框的集合H，初始化为包含全部N个框；建造一个存放最优框的集合M，初始化为空集。

1、将所有集合 H 中的框进行==排序==，选出分数最高的框 m，从集合 H 移到集合 M；（每次移动置信度最高）

2、遍历集合 H 中的框，分别与框 m 计算==IoU==，如果高于某个==阈值==（一般为0~0.5），则认为此框与 m 重叠，将此框从集合 H 中去除。（从候选集合去重，即这个迭代过程动态调整H到M的候选数目）

3、回到第1步进行迭代，直到集合 H 为空。集合 M 中的框为我们所需。

==**Q: nms的参数有哪些？**==

### YOLOv8
Ultralytics

1. 提供了一个全新的 SOTA 模型，包括 P5 640 和 P6 1280 分辨率的目标检测网络和基于 YOLACT 的实例分割模型。和 YOLOv5 一样，基于缩放系数也提供了 N/S/M/L/X 尺度的不同大小模型，用于满足不同场景需求
    
2. 骨干网络和 Neck 部分可能参考了 YOLOv7 ELAN 设计思想，将 YOLOv5 的 C3 结构换成了梯度流更丰富的 **C2f** 结构，并对**不同尺度模型调整了不同的通道数**，属于对模型结构精心微调，不再是无脑一套参数应用所有模型，大幅提升了模型性能。不过这个 C2f 模块中存在 Split 等操作对特定硬件部署没有之前那么友好了
    
3. Head 部分相比 YOLOv5 改动较大，换成了目前主流的==解耦头==结构，将==分类和检测头分离==，同时也从 Anchor-Based 换成了 Anchor-Free
    
4. Loss 计算方面采用了 TaskAlignedAssigner 正样本分配策略，并引入了 Distribution Focal Loss
    TaskAlignedAssigner 的匹配策略简单总结为： 根据分类与回归的分数加权的分数选择正样本。$$
    t=s^{\alpha}+u^{\beta}
    $$`s` 是标注类别对应的预测分值，`u` 是预测框和 gt 框的 iou，两者相乘就可以衡量对齐程度。
    Loss 计算包括 2 个分支： **分类和回归分支，没有了之前的 objectness 分支**。
	- 分类分支依然采用 **BCE Loss**
	- 回归分支需要和 Distribution Focal Loss 中提出的积分形式表示法绑定，因此使用了 **Distribution Focal Loss**， 同时还使用了 **CIoU Loss**

5. 训练的数据增强部分引入了 YOLOX 中的最后 10 epoch 关闭 Mosiac 增强的操作，可以有效地提升精度





### DETR

将匹配问题描述成==二部图的最小匹配问题==

匈牙利算法，也称为Kuhn-Munkres算法，是一种用于解决指派问题（Assignment Problem）的优化算法。指派问题是一种组合优化问题，通常描述为在给定的成本矩阵中找到使总成本最小的一组指派。一种一对一的匹配，使n x n的成本矩阵成本最小。

数学原理如下：

1. **成本矩阵：** 假设有一个大小为 n x n 的成本矩阵 \(C\)，其中 \(C[i][j]\) 表示将任务 \(i\) 分配给工作 \(j\) 的成本。我们的目标是找到一组指派，使总成本最小。

2. **初始化：** 通过在每行上减去该行的最小值，再在每列上减去该列的最小值，将成本矩阵转化为具有零元素的最佳初始解。这个过程称为减去行最小值和列最小值。

3. **标记零元素：** 对每行和每列中的每个零元素进行标记。标记过程要确保每行和每列最多只有一个零元素被标记。

4. **尝试找到最小的行/列数：** 尝试找到最小的行数或列数，以便能够选中足够数量的零元素，使得每行和每列都至少有一个被标记的零元素。如果找到，则转到下一步；否则，进行下一步。

5. **找到增广路径：** 通过从未被标记的零元素出发，尝试找到一条交替出现的路径，该路径包含标记和未标记的零元素。如果找到增广路径，则进行下一步；否则，进行下一步。

6. **调整：** 通过调整已标记的元素和未标记的元素，使得标记的元素变多，未标记的元素变少。这个过程称为调整。

7. **重复步骤：** 重复步骤4-6，直到找到最优解。

8. **解释结果：** 解释最终的标记和未标记元素，以得到最优指派方案。

匈牙利算法保证找到的解是全局最优的，且具有多项式时间复杂度$n^3$。这种算法在许多领域，如任务分配、资源分配等方面有广泛应用。

DETR, MaskFormer都是用匈牙利算法来解决二向图匹配问题和设计loss。
$$ L_{Hungarian}(L_{class} + L_{box})$$
cls交叉熵，box是IoU loss和均方差

> Most modern object detection methods make predictions relative to some ini-
tial guesses. (RPN, anchor/grid)

>In our model we are able to remove this hand-crafted process and streamline the
detection process by **directly** predicting the set of detections with absolute box
prediction w.r.t. the input image rather than an anchor.

减少先验

CNN编码的feature同pos embedding结合输入encoder，
N个object queries作为decoder输入，得到N个embedding输出，每个经过FFN得到一个目标，
包括class和box
## 量化

量化，混合精度训练，FP32